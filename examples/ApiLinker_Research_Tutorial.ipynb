{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ApiLinker Research Tutorial\n",
        "\n",
        "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/kkartas/APILinker/HEAD?labpath=examples%2FApiLinker_Research_Tutorial.ipynb)\n",
        "\n",
        "**üöÄ Try this notebook in your browser!** Click the Binder badge above to launch an interactive version of this tutorial (no installation required).\n",
        "\n",
        "---\n",
        "\n",
        "This notebook demonstrates how to use ApiLinker for research workflows, including literature searches, data integration, and cross-platform research.\n",
        "\n",
        "## Table of Contents\n",
        "1. [Installation and Setup](#installation)\n",
        "2. [Basic API Integration](#basic-integration)\n",
        "3. [Research Connectors](#research-connectors)\n",
        "4. [Literature Search Workflow](#literature-search)\n",
        "5. [Data Transformation and Mapping](#data-transformation)\n",
        "6. [Cross-Platform Research](#cross-platform)\n",
        "7. [Visualization Examples](#visualization)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installation and Setup {#installation}\n",
        "\n",
        "First, let's install ApiLinker and import the necessary modules.\n",
        "\n",
        "**Note for Binder users**: ApiLinker should be automatically installed from the repository. If you encounter import errors, the installation may have failed. Check the Binder build logs or try restarting the kernel.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Note: If running on Binder, ApiLinker is already installed!\n",
        "# If running locally, uncomment the line below:\n",
        "# !pip install apilinker\n",
        "\n",
        "# Diagnostic information\n",
        "import sys\n",
        "import os\n",
        "print(\"Python version:\", sys.version)\n",
        "print(\"Python path:\", sys.executable)\n",
        "print()\n",
        "\n",
        "# Import ApiLinker (always available)\n",
        "from apilinker import ApiLinker\n",
        "import apilinker\n",
        "\n",
        "print(f\"ApiLinker version: {apilinker.__version__}\")\n",
        "print(f\"ApiLinker location: {apilinker.__file__}\")\n",
        "print()\n",
        "\n",
        "# Check if connectors directory exists\n",
        "connectors_path = os.path.join(os.path.dirname(apilinker.__file__), 'connectors')\n",
        "if os.path.exists(connectors_path):\n",
        "    print(f\"‚úÖ Connectors directory found: {connectors_path}\")\n",
        "    print(f\"   Contents: {os.listdir(connectors_path)}\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è  Connectors directory not found at: {connectors_path}\")\n",
        "print()\n",
        "\n",
        "# Try to import research connectors (may not be available in older versions)\n",
        "try:\n",
        "    from apilinker import (\n",
        "        NCBIConnector, ArXivConnector, CrossRefConnector,\n",
        "        SemanticScholarConnector, PubChemConnector, ORCIDConnector,\n",
        "        GitHubConnector, NASAConnector\n",
        "    )\n",
        "    RESEARCH_CONNECTORS_AVAILABLE = True\n",
        "    print(\"‚úÖ ApiLinker and all research connectors imported successfully!\")\n",
        "except ImportError as e:\n",
        "    RESEARCH_CONNECTORS_AVAILABLE = False\n",
        "    print(f\"‚ö†Ô∏è  ApiLinker imported, but research connectors are not available.\")\n",
        "    print(f\"   Error: {e}\")\n",
        "    print()\n",
        "    print(\"   Debugging information:\")\n",
        "    # Try direct import to see the actual error\n",
        "    try:\n",
        "        from apilinker.connectors.scientific.ncbi import NCBIConnector\n",
        "        print(\"   ‚úÖ Direct import from connectors.scientific.ncbi works!\")\n",
        "        print(\"   ‚ö†Ô∏è  Issue is likely in __init__.py import handling\")\n",
        "    except Exception as direct_error:\n",
        "        print(f\"   ‚ùå Direct import also failed: {direct_error}\")\n",
        "    print()\n",
        "    print(\"   This may happen if:\")\n",
        "    print(\"   - Using an older version from PyPI\")\n",
        "    print(\"   - The repository installation didn't include connectors\")\n",
        "    print(\"   - There's an import error in the connector modules\")\n",
        "    print()\n",
        "    print(\"   On Binder, check the build logs to see if installation succeeded.\")\n",
        "    print(\"   You can still use ApiLinker for general API integration!\")\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "from datetime import datetime\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Basic API Integration {#basic-integration}\n",
        "\n",
        "Let's start with a simple example of connecting two APIs and mapping data between them.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize ApiLinker\n",
        "linker = ApiLinker()\n",
        "\n",
        "# Example: Connect to a public API (no authentication required)\n",
        "linker.add_source(\n",
        "    type=\"rest\",\n",
        "    base_url=\"https://api.github.com\",\n",
        "    endpoints={\n",
        "        \"get_repo\": {\n",
        "            \"path\": \"/repos/kkartas/APILinker\",\n",
        "            \"method\": \"GET\"\n",
        "        }\n",
        "    }\n",
        ")\n",
        "\n",
        "# Fetch data\n",
        "repo_data = linker.fetch(\"get_repo\")\n",
        "\n",
        "# Display results\n",
        "print(f\"Repository: {repo_data.get('name')}\")\n",
        "print(f\"Description: {repo_data.get('description')}\")\n",
        "print(f\"Stars: {repo_data.get('stargazers_count')}\")\n",
        "print(f\"Language: {repo_data.get('language')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Research Connectors {#research-connectors}\n",
        "\n",
        "ApiLinker includes 8 specialized research connectors. Let's explore them:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize research connectors\n",
        "# Note: Some connectors require API keys or email addresses\n",
        "\n",
        "if not RESEARCH_CONNECTORS_AVAILABLE:\n",
        "    print(\"‚ùå Research connectors are not available. Please ensure you're using the latest version.\")\n",
        "    print(\"   On Binder, this should work automatically. If not, the repository may need to be updated.\")\n",
        "else:\n",
        "    # Scientific Literature\n",
        "    ncbi = NCBIConnector(email=\"researcher@university.edu\")  # Replace with your email\n",
        "    arxiv = ArXivConnector()  # No API key required\n",
        "    crossref = CrossRefConnector(email=\"researcher@university.edu\")\n",
        "    semantic = SemanticScholarConnector()  # Optional API key for higher rate limits\n",
        "    \n",
        "    # Chemical & Biological Data\n",
        "    pubchem = PubChemConnector()  # No API key required\n",
        "    orcid = ORCIDConnector()  # Public API, no key required\n",
        "    \n",
        "    # Code & Data\n",
        "    github = GitHubConnector()  # Optional token for higher rate limits\n",
        "    nasa = NASAConnector()  # Uses DEMO_KEY by default (limited rate, get your key from api.nasa.gov)\n",
        "    \n",
        "    print(\"‚úÖ All research connectors initialized!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Literature Search Workflow {#literature-search}\n",
        "\n",
        "Let's create a comprehensive literature search across multiple databases:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize variables (needed for visualization even if connectors aren't available)\n",
        "topic = \"machine learning protein folding\"\n",
        "pubmed_ids = []\n",
        "arxiv_results = []\n",
        "semantic_papers = []\n",
        "\n",
        "if not RESEARCH_CONNECTORS_AVAILABLE:\n",
        "    print(\"‚ö†Ô∏è  Research connectors are not available. Skipping this section.\")\n",
        "    print(\"   Please check the installation or use the basic API integration examples below.\")\n",
        "    print(f\"   (Topic would have been: {topic})\")\n",
        "else:\n",
        "    print(f\"üîç Searching for: {topic}\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Search PubMed (biomedical literature)\n",
        "    print(\"\\nüìö Searching PubMed...\")\n",
        "    try:\n",
        "        pubmed_results = ncbi.search_pubmed(topic, max_results=10)\n",
        "        pubmed_ids = pubmed_results.get('esearchresult', {}).get('idlist', [])\n",
        "        print(f\"   Found {len(pubmed_ids)} papers\")\n",
        "    except Exception as e:\n",
        "        print(f\"   Error: {e}\")\n",
        "        pubmed_ids = []\n",
        "    \n",
        "    # Search arXiv (preprints)\n",
        "    print(\"\\nüìÑ Searching arXiv...\")\n",
        "    try:\n",
        "        arxiv_results = arxiv.search_papers(topic, max_results=10)\n",
        "        print(f\"   Found {len(arxiv_results)} papers\")\n",
        "    except Exception as e:\n",
        "        print(f\"   Error: {e}\")\n",
        "        arxiv_results = []\n",
        "    \n",
        "    # Search Semantic Scholar\n",
        "    print(\"\\nü§ñ Searching Semantic Scholar...\")\n",
        "    try:\n",
        "        semantic_results = semantic.search_papers(topic, max_results=10)\n",
        "        semantic_papers = semantic_results.get('data', [])\n",
        "        print(f\"   Found {len(semantic_papers)} papers\")\n",
        "    except Exception as e:\n",
        "        print(f\"   Error: {e}\")\n",
        "        semantic_papers = []\n",
        "    \n",
        "    print(\"\\n‚úÖ Literature search complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualize Search Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a summary of results\n",
        "results_summary = {\n",
        "    'Database': ['PubMed', 'arXiv', 'Semantic Scholar'],\n",
        "    'Papers Found': [len(pubmed_ids), len(arxiv_results), len(semantic_papers)]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(results_summary)\n",
        "print(\"\\nüìä Search Results Summary:\")\n",
        "print(df.to_string(index=False))\n",
        "\n",
        "# Create a simple bar chart\n",
        "if len(df) > 0 and (len(pubmed_ids) > 0 or len(arxiv_results) > 0 or len(semantic_papers) > 0):\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.bar(df['Database'], df['Papers Found'], color=['#2E86AB', '#A23B72', '#F18F01'])\n",
        "    plt.title(f'Literature Search Results: {topic}')\n",
        "    plt.ylabel('Number of Papers')\n",
        "    plt.xlabel('Database')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "elif not RESEARCH_CONNECTORS_AVAILABLE:\n",
        "    print(\"\\n‚ö†Ô∏è  Visualization skipped: Research connectors are not available.\")\n",
        "    print(\"   Install ApiLinker from the repository to see search results visualization.\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è  No results to visualize. Try running the search cells above first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "1. **Explore the documentation**: Check out [docs/research_workflows.md](../docs/research_workflows.md)\n",
        "2. **Try more examples**: See [examples/comprehensive_research_examples.py](../examples/comprehensive_research_examples.py)\n",
        "3. **Configure your APIs**: Set up API keys for higher rate limits\n",
        "4. **Create your own workflows**: Use ApiLinker to automate your research data collection\n",
        "\n",
        "## Resources\n",
        "\n",
        "- **GitHub**: https://github.com/kkartas/APILinker\n",
        "- **Documentation**: https://apilinker.readthedocs.io/\n",
        "- **PyPI**: https://pypi.org/project/apilinker/\n",
        "\n",
        "---\n",
        "\n",
        "*This notebook demonstrates ApiLinker's capabilities for research workflows. Modify the examples to fit your research needs!*\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
