{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ApiLinker Research Tutorial\n",
        "\n",
        "This notebook demonstrates how to use ApiLinker for research workflows, including literature searches, data integration, and cross-platform research.\n",
        "\n",
        "## Table of Contents\n",
        "1. [Installation and Setup](#installation)\n",
        "2. [Basic API Integration](#basic-integration)\n",
        "3. [Research Connectors](#research-connectors)\n",
        "4. [Literature Search Workflow](#literature-search)\n",
        "5. [Data Transformation and Mapping](#data-transformation)\n",
        "6. [Cross-Platform Research](#cross-platform)\n",
        "7. [Visualization Examples](#visualization)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installation and Setup {#installation}\n",
        "\n",
        "First, let's install ApiLinker and import the necessary modules.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install ApiLinker (uncomment if needed)\n",
        "# !pip install apilinker\n",
        "\n",
        "# Import ApiLinker and research connectors\n",
        "from apilinker import ApiLinker\n",
        "from apilinker import (\n",
        "    NCBIConnector, ArXivConnector, CrossRefConnector,\n",
        "    SemanticScholarConnector, PubChemConnector, ORCIDConnector,\n",
        "    GitHubConnector, NASAConnector\n",
        ")\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"âœ… ApiLinker imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Basic API Integration {#basic-integration}\n",
        "\n",
        "Let's start with a simple example of connecting two APIs and mapping data between them.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize ApiLinker\n",
        "linker = ApiLinker()\n",
        "\n",
        "# Example: Connect to a public API (no authentication required)\n",
        "linker.add_source(\n",
        "    type=\"rest\",\n",
        "    base_url=\"https://api.github.com\",\n",
        "    endpoints={\n",
        "        \"get_repo\": {\n",
        "            \"path\": \"/repos/kkartas/APILinker\",\n",
        "            \"method\": \"GET\"\n",
        "        }\n",
        "    }\n",
        ")\n",
        "\n",
        "# Fetch data\n",
        "repo_data = linker.fetch(\"get_repo\")\n",
        "\n",
        "# Display results\n",
        "print(f\"Repository: {repo_data.get('name')}\")\n",
        "print(f\"Description: {repo_data.get('description')}\")\n",
        "print(f\"Stars: {repo_data.get('stargazers_count')}\")\n",
        "print(f\"Language: {repo_data.get('language')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Research Connectors {#research-connectors}\n",
        "\n",
        "ApiLinker includes 8 specialized research connectors. Let's explore them:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize research connectors\n",
        "# Note: Some connectors require API keys or email addresses\n",
        "\n",
        "# Scientific Literature\n",
        "ncbi = NCBIConnector(email=\"researcher@university.edu\")  # Replace with your email\n",
        "arxiv = ArXivConnector()  # No API key required\n",
        "crossref = CrossRefConnector(email=\"researcher@university.edu\")\n",
        "semantic = SemanticScholarConnector()  # Optional API key for higher rate limits\n",
        "\n",
        "# Chemical & Biological Data\n",
        "pubchem = PubChemConnector()  # No API key required\n",
        "orcid = ORCIDConnector()  # Public API, no key required\n",
        "\n",
        "# Code & Data\n",
        "github = GitHubConnector()  # Optional token for higher rate limits\n",
        "nasa = NASAConnector()  # Requires API key from api.nasa.gov\n",
        "\n",
        "print(\"âœ… All research connectors initialized!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Literature Search Workflow {#literature-search}\n",
        "\n",
        "Let's create a comprehensive literature search across multiple databases:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Research topic\n",
        "topic = \"machine learning protein folding\"\n",
        "\n",
        "print(f\"ðŸ” Searching for: {topic}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Search PubMed (biomedical literature)\n",
        "print(\"\\nðŸ“š Searching PubMed...\")\n",
        "try:\n",
        "    pubmed_results = ncbi.search_pubmed(topic, max_results=10)\n",
        "    pubmed_ids = pubmed_results.get('esearchresult', {}).get('idlist', [])\n",
        "    print(f\"   Found {len(pubmed_ids)} papers\")\n",
        "except Exception as e:\n",
        "    print(f\"   Error: {e}\")\n",
        "    pubmed_ids = []\n",
        "\n",
        "# Search arXiv (preprints)\n",
        "print(\"\\nðŸ“„ Searching arXiv...\")\n",
        "try:\n",
        "    arxiv_results = arxiv.search_papers(topic, max_results=10)\n",
        "    print(f\"   Found {len(arxiv_results)} papers\")\n",
        "except Exception as e:\n",
        "    print(f\"   Error: {e}\")\n",
        "    arxiv_results = []\n",
        "\n",
        "# Search Semantic Scholar\n",
        "print(\"\\nðŸ¤– Searching Semantic Scholar...\")\n",
        "try:\n",
        "    semantic_results = semantic.search_papers(topic, max_results=10)\n",
        "    semantic_papers = semantic_results.get('data', [])\n",
        "    print(f\"   Found {len(semantic_papers)} papers\")\n",
        "except Exception as e:\n",
        "    print(f\"   Error: {e}\")\n",
        "    semantic_papers = []\n",
        "\n",
        "print(\"\\nâœ… Literature search complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualize Search Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a summary of results\n",
        "results_summary = {\n",
        "    'Database': ['PubMed', 'arXiv', 'Semantic Scholar'],\n",
        "    'Papers Found': [len(pubmed_ids), len(arxiv_results), len(semantic_papers)]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(results_summary)\n",
        "print(\"\\nðŸ“Š Search Results Summary:\")\n",
        "print(df.to_string(index=False))\n",
        "\n",
        "# Create a simple bar chart\n",
        "if len(df) > 0:\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.bar(df['Database'], df['Papers Found'], color=['#2E86AB', '#A23B72', '#F18F01'])\n",
        "    plt.title(f'Literature Search Results: {topic}')\n",
        "    plt.ylabel('Number of Papers')\n",
        "    plt.xlabel('Database')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "1. **Explore the documentation**: Check out [docs/research_workflows.md](../docs/research_workflows.md)\n",
        "2. **Try more examples**: See [examples/comprehensive_research_examples.py](../examples/comprehensive_research_examples.py)\n",
        "3. **Configure your APIs**: Set up API keys for higher rate limits\n",
        "4. **Create your own workflows**: Use ApiLinker to automate your research data collection\n",
        "\n",
        "## Resources\n",
        "\n",
        "- **GitHub**: https://github.com/kkartas/APILinker\n",
        "- **Documentation**: https://apilinker.readthedocs.io/\n",
        "- **PyPI**: https://pypi.org/project/apilinker/\n",
        "\n",
        "---\n",
        "\n",
        "*This notebook demonstrates ApiLinker's capabilities for research workflows. Modify the examples to fit your research needs!*\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
